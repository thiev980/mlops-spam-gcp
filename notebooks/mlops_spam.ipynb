{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56b1268",
   "metadata": {},
   "source": [
    "# Part 1: Theory\n",
    "We trained a classifier… now what?\n",
    "\n",
    "https://medium.com/@vivek.bharti31/from-notebook-to-production-what-most-ml-tutorials-dont-teach-5bdea33b20bb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ac955",
   "metadata": {},
   "source": [
    "# Part 2: Build the Spam Classifier\n",
    "\n",
    "In this post, we’ll train a spam classifier using the SMS Spam Collection dataset — but we’ll take a production-minded, real-world approach at every step. That means:\n",
    "\n",
    "✅ Creating a holdout set for final evaluation\n",
    "✅ Preprocessing the data robustly\n",
    "✅ Comparing multiple models with real-world tradeoffs\n",
    "✅ Optimizing for the right evaluation metric\n",
    "✅ Saving the model for real-world deployment\n",
    "\n",
    "https://medium.com/@vivek.bharti31/build-a-spam-classifier-like-a-production-ml-engineer-05acb540c9c3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687340af",
   "metadata": {},
   "source": [
    "## Step 1: Load & Explore the SMS Spam Dataset (UCI Repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9fa009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/SMSSpamCollection\", sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "print(df.label.value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecac088",
   "metadata": {},
   "source": [
    "## Step 2: Create a Holdout Set (To Mimic the Real World)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dde9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most tutorials split into train/test. But in production, you almost always need an unseen holdout set — \n",
    "# data that stays hidden until the very end. This helps evaluate your final model more realistically.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train_val, df_holdout = train_test_split(\n",
    "    df, test_size=0.1, stratify=df['label'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f28d1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these to disk to simulate a real ML pipeline where training, testing, and deployment can be handled separately\n",
    "df_train_val.to_csv('../data/raw/spam_train_val.csv', index=False)\n",
    "df_holdout.to_csv('../data/raw/spam_holdout.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaeb383",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa355848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/thi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/thi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>ham</td>\n",
       "      <td>Heehee that was so funny tho</td>\n",
       "      <td>heehe funni tho</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>ham</td>\n",
       "      <td>I don wake since. I checked that stuff and saw...</td>\n",
       "      <td>wake sinc check stuff saw true avail space pl ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dai what this da.. Can i send my resume to thi...</td>\n",
       "      <td>dai da send resum id</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>ham</td>\n",
       "      <td>U too...</td>\n",
       "      <td>u</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ham</td>\n",
       "      <td>Didn't you get hep b immunisation in nigeria.</td>\n",
       "      <td>didnt get hep b immunis nigeria</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "3398   ham                       Heehee that was so funny tho   \n",
       "3325   ham  I don wake since. I checked that stuff and saw...   \n",
       "2498   ham  Dai what this da.. Can i send my resume to thi...   \n",
       "1553   ham                                           U too...   \n",
       "46     ham      Didn't you get hep b immunisation in nigeria.   \n",
       "\n",
       "                                             clean_text  label_num  \n",
       "3398                                    heehe funni tho          0  \n",
       "3325  wake sinc check stuff saw true avail space pl ...          0  \n",
       "2498                               dai da send resum id          0  \n",
       "1553                                                  u          0  \n",
       "46                      didnt get hep b immunis nigeria          0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string, nltk\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stopwords.words('english')]\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(t) for t in tokens]\n",
    "    return ' '.join(tokens)\n",
    "df_train_val['clean_text'] = df_train_val['text'].apply(preprocess_text)\n",
    "df_train_val['label_num'] = df_train_val['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "df_train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8d719e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test \n",
    "\n",
    "X = df_train_val['clean_text']\n",
    "y = df_train_val['label_num']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a8a9a0",
   "metadata": {},
   "source": [
    "## Step 4: Train and Compare Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50fda4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       869\n",
      "           1       0.92      0.92      0.92       134\n",
      "\n",
      "    accuracy                           0.98      1003\n",
      "   macro avg       0.96      0.95      0.95      1003\n",
      "weighted avg       0.98      0.98      0.98      1003\n",
      "\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       869\n",
      "           1       0.97      0.90      0.93       134\n",
      "\n",
      "    accuracy                           0.98      1003\n",
      "   macro avg       0.98      0.95      0.96      1003\n",
      "weighted avg       0.98      0.98      0.98      1003\n",
      "\n",
      "\n",
      "Model: MultinomialNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       869\n",
      "           1       1.00      0.68      0.81       134\n",
      "\n",
      "    accuracy                           0.96      1003\n",
      "   macro avg       0.98      0.84      0.89      1003\n",
      "weighted avg       0.96      0.96      0.95      1003\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       869\n",
      "           1       0.99      0.73      0.84       134\n",
      "\n",
      "    accuracy                           0.96      1003\n",
      "   macro avg       0.98      0.87      0.91      1003\n",
      "weighted avg       0.96      0.96      0.96      1003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    'SVM': SVC(kernel='linear', class_weight='balanced', probability=True),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, class_weight='balanced'),\n",
    "}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "        ('clf', clf),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fef367",
   "metadata": {},
   "source": [
    "Result (from tutorial): Logistic Regression gave the best balance of precision and recall, especially for the minority spam class (1). SVM, although it had slightly higher overall accuracy but had lower recall than the logistic regression, so we selected the logistic regression as our final model. In this case, **recall is more important as we don’t want to misclassify the spam as ham**, since missing a spam message is worse than misclassifying a ham – even if it means slightly more false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af57b2",
   "metadata": {},
   "source": [
    "### Optional: Grid Search for Spam Recall\n",
    "To validate our default model and see if hyperparameter tuning might yield improvement, we ran a grid search using GridSearchCV, scoring by recall on the spam class. This helps us ensure we're not missing a better configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db6ed859",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/thi/Data Science/Projects/mlops_spam/venv/lib/python3.13/site-packages/sklearn/utils/_repr_html/estimator.js'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science/Projects/mlops_spam/venv/lib/python3.13/site-packages/IPython/core/formatters.py:1036\u001b[39m, in \u001b[36m__call__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science/Projects/mlops_spam/venv/lib/python3.13/site-packages/sklearn/utils/_repr_html/base.py:151\u001b[39m, in \u001b[36m_repr_mimebundle_\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science/Projects/mlops_spam/venv/lib/python3.13/site-packages/sklearn/utils/_repr_html/estimator.py:489\u001b[39m, in \u001b[36mestimator_html_repr\u001b[39m\u001b[34m(estimator)\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/thi/Data Science/Projects/mlops_spam/venv/lib/python3.13/site-packages/sklearn/utils/_repr_html/estimator.js'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/thi/Data Science/Projects/mlops_spam/venv/lib/python3.13/site-packages/sklearn/utils/_repr_html/estimator.js'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science/Projects/mlops_spam/venv/lib/python3.13/site-packages/IPython/core/formatters.py:406\u001b[39m, in \u001b[36m__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science/Projects/mlops_spam/venv/lib/python3.13/site-packages/sklearn/utils/_repr_html/base.py:145\u001b[39m, in \u001b[36m_repr_html_inner\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Data Science/Projects/mlops_spam/venv/lib/python3.13/site-packages/sklearn/utils/_repr_html/estimator.py:489\u001b[39m, in \u001b[36mestimator_html_repr\u001b[39m\u001b[34m(estimator)\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/thi/Data Science/Projects/mlops_spam/venv/lib/python3.13/site-packages/sklearn/utils/_repr_html/estimator.js'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           solver='liblinear'))]),\n",
       "             param_grid={'clf__C': [0.01, 0.1, 1, 10],\n",
       "                         'clf__class_weight': [None, 'balanced']},\n",
       "             scoring=make_scorer(recall_score, response_method='predict', pos_label=1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "\n",
    "param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='liblinear')),\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, scoring=make_scorer(recall_score, pos_label=1), cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4865ed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'clf__C': 10, 'clf__class_weight': 'balanced'}\n",
      "Best Recall Score: 0.9088785046728972\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best Recall Score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a783a",
   "metadata": {},
   "source": [
    "Model Selection Note (from tutorial): While the best grid search model had slightly higher precision, the default model had better recall (92%). Since our primary goal is catching spam, we chose the default model. This emphasizes that in ML for production, it’s not about the most optimized score — it’s about optimizing for the right business metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0678c",
   "metadata": {},
   "source": [
    "## Step 5: Retrain on Full Data and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47540578",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.concat([X_train, X_test])\n",
    "y_full = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f73a63",
   "metadata": {},
   "source": [
    "We now save the trained model as a pipeline that includes both the TF-IDF vectorizer and the logistic regression classifier. This ensures the exact same preprocessing steps are applied during inference, making deployment seamless and reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b2cf750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Ordner anlegen, falls nicht vorhanden\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "final_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression(class_weight='balanced', max_iter=1000)),\n",
    "])\n",
    "final_model.fit(X_full, y_full)\n",
    "with open('../models/logreg_spam_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c634e",
   "metadata": {},
   "source": [
    "## Step 6: Final Check on Holdout Set\n",
    "Our last step: test the model on our untouched holdout set. This final evaluation step ensures that the model generalizes well and hasn’t overfitted to the training or test data. Based on the results, we observe strong performance with no signs of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a197309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       483\n",
      "           1       0.88      0.89      0.89        75\n",
      "\n",
      "    accuracy                           0.97       558\n",
      "   macro avg       0.93      0.94      0.93       558\n",
      "weighted avg       0.97      0.97      0.97       558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_holdout = pd.read_csv('../data/raw/spam_holdout.csv')\n",
    "df_holdout['label_num'] = df_holdout['label'].map({'ham': 0, 'spam': 1})\n",
    "df_holdout['clean_text'] = df_holdout['text'].apply(preprocess_text)\n",
    "\n",
    "with open('../models/logreg_spam_pipeline.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "X_holdout = df_holdout['clean_text']\n",
    "y_holdout = df_holdout['label_num']\n",
    "y_pred = model.predict(X_holdout)\n",
    "print(classification_report(y_holdout, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da3ad1",
   "metadata": {},
   "source": [
    " Final Results on Holdout Set: The model achieved 97% accuracy and 89% recall on the spam class — confirming strong generalization to unseen data. This is a solid indicator that the pipeline is production-ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24296b6",
   "metadata": {},
   "source": [
    "# Part 3: Serving ML with Flask: Your First Spam Detection API\n",
    "\n",
    "In this post, we’ll build a lightweight Flask API that takes an SMS message and tells you whether it’s spam — in real time.\n",
    "\n",
    "https://medium.com/@vivek.bharti31/serving-ml-with-flask-your-first-spam-detection-api-7f0a1669726e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6802d",
   "metadata": {},
   "source": [
    "### Why APIs Matter for ML\n",
    "\n",
    "Most machine learning models never make it into production. When they do, it’s usually through an API — a simple, structured interface that lets other software talk to your model.\n",
    "\n",
    "Whether it’s a web app, a mobile app, or a data pipeline, an API makes your model accessible to the world. Even a lightweight Flask app is a huge step toward production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b018754b",
   "metadata": {},
   "source": [
    "### Quick Intro to Flask\n",
    "\n",
    "Flask is a micro web framework in Python. It’s ideal for rapid prototyping and ML demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd5814ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from flask import Flask\\n\\napp = Flask(__name__)\\n@app.route(\\'/\\')\\ndef home():\\n    return \"Hello, world!\"\\nif __name__ == \\'__main__\\':\\n    app.run(debug=True)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# app.py\n",
    "\n",
    "'''from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"Hello, world!\"\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5446cc9",
   "metadata": {},
   "source": [
    "With just a few lines, you’ve spun up a working web server. Now let’s connect this to our saved spam classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d2de89",
   "metadata": {},
   "source": [
    "### Load the Model and Handle Predictions\n",
    "\n",
    "We load our trained model and reuse the same text preprocessing logic before serving predictions.\n",
    "\n",
    "We’ll load the model pipeline we saved earlier — it already includes both the TF-IDF vectorizer and the logistic regression classifier. We’ll also apply the same preprocessing steps as in training, and apply a custom threshold for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from flask import Flask, request, jsonify\n",
    "import pickle'''\n",
    "\n",
    "# --- Optional: NLTK nur, wenn du wirklich manuell tokenizest ---\n",
    "# import nltk\n",
    "# nltk.download('punkt', quiet=True)\n",
    "# nltk.download('stopwords', quiet=True)\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "'''app = Flask(__name__)\n",
    "\n",
    "# Modell laden (Pipeline mit Tfidf + LogisticRegression)\n",
    "with open('models/logreg_spam_pipeline.pkl', 'rb') as f:\n",
    "    logreg_pipeline = pickle.load(f)\n",
    "\n",
    "BEST_THRESHOLD = 0.620\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return jsonify(status=\"ok\", message=\"Spam API is running\"), 200\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(silent=True) or {}\n",
    "    text = data.get('text')\n",
    "    if not text:\n",
    "        return jsonify({'error': 'No text provided'}), 400\n",
    "\n",
    "    # Empfehlung: Rohtext direkt an die Pipeline geben,\n",
    "    # damit Preprocessing identisch zu Training bleibt.\n",
    "    prob = logreg_pipeline.predict_proba([text])[0][1]\n",
    "    pred = int(prob >= BEST_THRESHOLD)\n",
    "    label = 'spam' if pred == 1 else 'ham'\n",
    "    return jsonify({'prediction': label, 'probability_spam': prob})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Debug ok, aber Reloader aus, damit nichts doppelt läuft\n",
    "    app.run(debug=True, use_reloader=False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84ebaf3",
   "metadata": {},
   "source": [
    "This API accepts POST requests with a JSON payload like { \"text\": \"You've won a free prize! Click here\" } and returns whether it’s spam/ham."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7249383e",
   "metadata": {},
   "source": [
    "### Running the API Locally\n",
    "\n",
    "To start the Flask server, run the following command from the terminal in the same directory as your app.py file: \n",
    "\n",
    "python3 app.py\n",
    "\n",
    "By default, this will launch the API at http://localhost:5000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d5b2d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8f03b3e",
   "metadata": {},
   "source": [
    "### Test with Postman or cURL\n",
    "\n",
    "Once your Flask server is running, you can test it using:\n",
    "Postman (GUI tool)\n",
    "\n",
    "Postman is a popular desktop app that helps developers test APIs without writing code. It provides a user-friendly interface to craft requests and view responses.\n",
    "\n",
    "Steps:\n",
    "\n",
    "    Open Postman and set the method to POST\n",
    "    URL: http://localhost:5000/predict\n",
    "    Go to the Body tab → select raw → choose JSON\n",
    "    Paste this JSON:\n",
    "\n",
    "{ \"text\": \"You've won a free prize! Click here\" }\n",
    "\n",
    "Click Send and check the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f94777",
   "metadata": {},
   "source": [
    "### cURL (Command Line Tool)\n",
    "\n",
    "If you prefer the terminal, cURL is a command-line tool to send HTTP requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db594b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'curl -X POST http://localhost:5000/predict      -H \"Content-Type: application/json\"      -d \\'{\"text\": \"You’ve won a free prize! Click here\"}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''curl -X POST http://localhost:5000/predict \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"text\": \"You’ve won a free prize! Click here\"}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc087be7",
   "metadata": {},
   "source": [
    "### Security and Production Tips\n",
    "\n",
    "This is a minimal setup — perfect for learning, but not secure for public exposure. Here are a few things to keep in mind:\n",
    "\n",
    "    Add input validation and logging\n",
    "    Limit request size and rate\n",
    "    Disable debug mode in production\n",
    "    Consider using gunicorn or uvicorn for deployment\n",
    "    Eventually, containerize your app with Docker or deploy it to a cloud platform like AWS, GCP, or Heroku using production-grade servers like Gunicorn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc842c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6b9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173fe600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
